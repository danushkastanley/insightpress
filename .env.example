# InsightPress Configuration

# Output settings
OUTPUT_DIR=output
CACHE_DIR=cache

# Collection settings
MAX_ITEMS=30
DRAFTS_COUNT=4
HN_STORY_TYPE=beststories  # beststories or topstories
HN_MAX_STORIES=50

# Ranking settings
TOPICS=ai,llm,kubernetes,devops,security,mlops,rust,python,aws,observability
RECENCY_HOURS=72

# Source weights (higher = more important)
WEIGHT_HN=1.0
WEIGHT_RSS_DEFAULT=0.8

# Draft generation
HASHTAGS_MAX=3
DRAFT_STYLE=technical  # technical or casual
CHAR_LIMIT=260  # Hard character limit for X posts (headroom for edits)

# LLM Provider Settings (optional - for AI-powered drafting)
# Default is 'none' (template-based drafting)
LLM_PROVIDER=none  # none|openai|anthropic|gemini
LLM_MODEL=  # Optional: provider-specific model name (uses defaults if empty)
LLM_TEMPERATURE=0.2  # Lower = more deterministic (0.0-1.0)
LLM_MAX_RETRIES=2  # Retry attempts if LLM generation fails
LLM_TIMEOUT_SECS=20  # Request timeout in seconds

# API Keys (only needed if using LLM providers)
# Never commit these keys to git!
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GEMINI_API_KEY=

# Network settings
REQUEST_TIMEOUT=10
USER_AGENT=insightpress/0.1

# Logging
LOG_LEVEL=INFO
